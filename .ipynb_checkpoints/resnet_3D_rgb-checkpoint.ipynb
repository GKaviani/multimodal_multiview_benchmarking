{
 "cells": [
  {
   "cell_type": "code",
   "id": "ac37a7833024fdde",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-15T18:17:04.090596Z",
     "start_time": "2024-05-15T18:17:01.338405Z"
    }
   },
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from PIL import Image\n",
    "import random\n",
    "from utils import plot_sequences\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "from torch import nn, optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision.models.video import r3d_18\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "set_seed(0)"
   ],
   "id": "4f8d3e6ebd3ee2bd",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "class Custom3DDataset(Dataset):\n",
    "    def __init__(self, root_dir, sequence_length=16, sampling=\"single-random\", transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.sequence_length = sequence_length\n",
    "        self.transform = transform\n",
    "        self.sampling = sampling\n",
    "        self.sequences = self._create_sequences()\n",
    "\n",
    "    def _create_sequences(self):\n",
    "        sequences = []\n",
    "        for activity in os.listdir(self.root_dir):\n",
    "            activity_dir = os.path.join(self.root_dir, activity)\n",
    "            frames = sorted(glob(os.path.join(activity_dir, '*.png')))\n",
    "            grouped_frames = self._group_frames_by_subject_and_session(frames)\n",
    "            for subject_session in grouped_frames.keys():\n",
    "                frames = grouped_frames.get(subject_session, [])\n",
    "                if len(frames) < self.sequence_length:\n",
    "                    # Pad the sequence\n",
    "                    sequence = self._pad_sequence(frames)\n",
    "                    sequences.append((sequence, activity))\n",
    "                else:\n",
    "                    if self.sampling == \"multiple-consecutive\":\n",
    "                        for i in range(0, len(frames) - self.sequence_length + 1):\n",
    "                            sequence = frames[i:i + self.sequence_length]\n",
    "                            sequences.append((sequence, activity))\n",
    "                    elif self.sampling == \"multiple-random\":\n",
    "                        for _ in range(0, len(frames) - self.sequence_length + 1):\n",
    "                            start_idx = random.randint(0, len(frames) - self.sequence_length)\n",
    "                            sequence = frames[start_idx:start_idx + self.sequence_length]\n",
    "                            sequences.append((sequence, activity))\n",
    "                    elif self.sampling == \"single-random\":\n",
    "                        sequence = sorted(random.sample(frames, self.sequence_length))\n",
    "                        sequences.append((sequence, activity))\n",
    "                # print(f'Grouped sequence {subject_session} {activity}: {sequence}')  # Print the grouped sequence\n",
    "        return sequences\n",
    "\n",
    "    def _pad_sequence(self, frames):\n",
    "        if len(frames) == 0:\n",
    "            return frames  # Avoid division by zero if frames is empty\n",
    "        while len(frames) < self.sequence_length:\n",
    "            frames.append(frames[-1])  # Repeat the last frame\n",
    "        return frames\n",
    "\n",
    "    def _group_frames_by_subject_and_session(self, frames):\n",
    "        grouped_frames = {}\n",
    "        for frame in frames:\n",
    "            filename = os.path.basename(frame)\n",
    "            subject_session = '_'.join(filename.split('_')[:2])\n",
    "            if subject_session not in grouped_frames:\n",
    "                grouped_frames[subject_session] = []\n",
    "            grouped_frames[subject_session].append(frame)\n",
    "        return grouped_frames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence, activity = self.sequences[idx]\n",
    "        frames = []\n",
    "        for frame_path in sequence:\n",
    "            image = Image.open(frame_path).convert('RGB')  # Convert to RGB\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            frames.append(image)\n",
    "        frames = torch.stack(frames)  # (T, C, H, W)\n",
    "        print(f\"frames shape {frames.shape}\")\n",
    "        label = self._get_label(activity)\n",
    "        return frames, label\n",
    "\n",
    "    def _get_label(self, activity):\n",
    "        # Assuming class names are the activity names\n",
    "        class_names = sorted(os.listdir(self.root_dir))\n",
    "        label = class_names.index(activity)\n",
    "        return label\n",
    "\n",
    "\n",
    "# Define transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 171), interpolation=InterpolationMode.BILINEAR),\n",
    "    transforms.CenterCrop((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.43216, 0.394666, 0.37645], [0.22803, 0.22145, 0.216989])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 171), interpolation=InterpolationMode.BILINEAR),\n",
    "    transforms.CenterCrop((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.43216, 0.394666, 0.37645], [0.22803, 0.22145, 0.216989])\n",
    "])\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = Custom3DDataset(root_dir='/mnt/data-tmp/ghazal/DARai_DATA/rgb_dataset/train',\n",
    "                                transform=train_transforms)\n",
    "test_dataset = Custom3DDataset(root_dir='/mnt/data-tmp/ghazal/DARai_DATA/rgb_dataset/test', transform=test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "plot_sequences(train_dataset , 2)"
   ],
   "id": "initial_id",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize the 3D ResNet model\n",
    "model = r3d_18(weights = 'Default')\n",
    "\n",
    "# Modify the final fully connected layer to match the number of classes\n",
    "num_classes = len(os.listdir('/mnt/data-tmp/ghazal/DARai_DATA/rgb_dataset/train'))  # Assuming class names are in the train directory\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1)\n",
    "\n",
    "# Initialize TensorBoard SummaryWriter\n",
    "# writer = SummaryWriter('./runs/activity_classification')\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "        # if len(inputs.shape) == 4:\n",
    "        #     inputs = inputs.unsqueeze(1)  # Add channel dimension\n",
    "\n",
    "        inputs = inputs.to(device)  # (B, C, T, H, W)\n",
    "        print(f'input shape {inputs.shape}')\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Training epoch took: {epoch_time:.2f}s\")\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate_model(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
    "            # if len(inputs.shape) == 4:\n",
    "            #     inputs = inputs.unsqueeze(1)  # Add channel dimension\n",
    "\n",
    "            inputs = inputs.to(device)  # (B, C, T, H, W)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    epoch_acc = running_corrects.double() / len(val_loader.dataset)\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Validation epoch took: {epoch_time:.2f}s\")\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "num_epochs = 25\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc = train_model(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "    epoch_duration = time.time() - epoch_start_time\n",
    "    print(f\"Epoch {epoch} took: {epoch_duration:.2f}s\")\n",
    "\n",
    "    print(f'Training Loss: {train_loss:.4f} Acc: {train_acc:.4f}')\n",
    "    print(f'Validation Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "\n",
    "    # writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    # writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "    # writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "    # writer.add_scalar('Accuracy/val', val_acc, epoch)\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "model.load_state_dict(best_model_wts)\n",
    "# writer.close()\n",
    "\n",
    "torch.save(model.state_dict(), 'best_3d_resnet_model.pth')"
   ],
   "id": "f41cb999c962d259",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8d3dbf38649f2439",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
